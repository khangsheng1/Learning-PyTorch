{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkDLm6MCeTZZzX2p7d2DPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khangsheng1/Learning-PyTorch/blob/main/LearnPyTorch_IO/04_PyTorch_Custom_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "URL: https://www.learnpytorch.io/04_pytorch_custom_datasets/"
      ],
      "metadata": {
        "id": "ED9pbQ6N-Xi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[PyTorch Domain Libraries](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pytorch-domain-libraries.png)"
      ],
      "metadata": {
        "id": "b-UQfx7G-pwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What we are going to cover\n",
        "\n",
        "|Topic|Contents|\n",
        "|--|--|\n",
        "|**0. Importing PyTorch and setting up device-agnostic code**|Let's get PyTorch loaded and then follow best practice to setup our code to be device-agnostic.|\n",
        "|**1. Get data**|We're going to be using our own **custom dataset** of pizza, steak and sushi images.|\n",
        "|**2. Become one with the data (data preparation)**|At the beginning of any new machine learning problem, it's paramount to understand the data you're working with. Here we'll take some steps to figure out what data we have.|\n",
        "|**3. Transforming data**|Often, the data you get won't be 100% ready to use with a machine learning model, here we'll look at some steps we can take to *transform* our images so they're ready to be used with a model.|\n",
        "|**4. Loading data with `ImageFolder` (option 1)**|PyTorch has many in-built data loading functions for common types of data. `ImageFolder` is helpful if our images are in standard image classification format.|\n",
        "|**5. Loading image data with a custom Dataset**|What if PyTorch didn't have an in-built function to load data with? This is where we can build our own custom subclass of `torch.utils.data.Dataset`.|\n",
        "|**6. Other forms of transforms (data augmentation)**|Data augmentation is a common technique for expanding the diversity of your training data. Here we'll explore some of `torchvision`'s in-built data augmentation functions.|\n",
        "|**7. Model 0: TinyVGG without data augmentation**|By this stage, we'll have our data ready, let's build a model capable of fitting it. We'll also create some training and testing functions for training and evaluating our model.|\n",
        "|**8. Exploring loss curves**|Loss curves are a great way to see how your model is training/improving over time. They're also a good way to see if your model is **underfitting** or **overfitting**.|\n",
        "|**9. Model 1: TinyVGG with data augmentation**|By now, we've tried a model without, how about we try one with data augmentation?|\n",
        "|**10. Compare model results**|Let's compare our different models' loss curves and see which performed better and discuss some options for improving performance.|\n",
        "|**11. Making a prediction on a custom image**|Our model is trained to on a dataset of pizza, steak and sushi images. In this section we'll cover how to use our trained model to predict on an image *outside* of our existing dataset.|"
      ],
      "metadata": {
        "id": "cKKIjRXg-9TE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 Importhing PyTorch and setting up device agnostic code"
      ],
      "metadata": {
        "id": "SG6Pf9o1AfxR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tRyW3UyoSbL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9347bfd8-9926-41d3-d492-316d654e0624"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: this notebook requires torch >= 1.10.0\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "T_S0m96oFqIK",
        "outputId": "bcd4d0d9-8a8e-4821-ffc2-6290de13fbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Get data"
      ],
      "metadata": {
        "id": "SQMecNZlF3FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use the [Food101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/).\n",
        "\n",
        "* Original [torchvision.datasets.Food101](https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html)\n",
        "* LearnPyTorch.io custom notebook for formating [here](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb).\n",
        "* Zip of pizza, steak, and sushi images [here](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip)"
      ],
      "metadata": {
        "id": "9OQ8IAIwGIPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\")\n",
        "        zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "tgD1Te-lFzTH",
        "outputId": "a8d0035f-8d91-4501-bae8-e20946706f98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Become one with the data (data preperation)"
      ],
      "metadata": {
        "id": "75YpA4wzHbSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "JXv7XbAtHWTE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "zn3o5cTMH7k9",
        "outputId": "41c1c03e-32e1-499c-d917-6cd592f67c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in 'data/pizza_steak_sushi'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/train'.\n",
            "There are 0 directories and 78 images in 'data/pizza_steak_sushi/train/pizza'.\n",
            "There are 0 directories and 75 images in 'data/pizza_steak_sushi/train/steak'.\n",
            "There are 0 directories and 72 images in 'data/pizza_steak_sushi/train/sushi'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/test'.\n",
            "There are 0 directories and 25 images in 'data/pizza_steak_sushi/test/pizza'.\n",
            "There are 0 directories and 19 images in 'data/pizza_steak_sushi/test/steak'.\n",
            "There are 0 directories and 31 images in 'data/pizza_steak_sushi/test/sushi'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "830PK58EH-eq",
        "outputId": "e20e24ea-a43d-4bc4-8216-abb407aa6ecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s791nNLlIGH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}