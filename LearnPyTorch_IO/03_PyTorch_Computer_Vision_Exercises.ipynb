{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfbICoFfXH5BXydJbk3Mnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khangsheng1/Learning-PyTorch/blob/main/LearnPyTorch_IO/03_PyTorch_Computer_Vision_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "URL: https://www.learnpytorch.io/03_pytorch_computer_vision/"
      ],
      "metadata": {
        "id": "3mR5UtnVEWRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzdXVR1tye8i",
        "outputId": "e9dc7096-da91-4671-8730-dbfe4b7b8585"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.0+cu121\n",
            "torchvision version: 0.20.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q7XfxhJH24FH",
        "outputId": "c6acc9e8-eb64-4ba2-f1f6-9fdf886f8de9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 What are 3 areas in industry where computer vision is currently being used?\n",
        "\n",
        "1. Smartphones\n",
        "2. Modern cars\n",
        "3. Security cameras"
      ],
      "metadata": {
        "id": "H74mXsQ7pbrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Search \"what is overfitting in machine learning\" and write down a sentence about what you find.\n",
        "\n",
        "Overfitting in machine learning occurs when a model learns the training data too well, capturing noise and specific patterns that don't generalize to new, unseen data."
      ],
      "metadata": {
        "id": "YT5T4tYgpkkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. Note: there are lots of these, so don't worry too much about all of them, just pick 3 and start with those.\n",
        "\n",
        "1. **Cross-Validation**: This method divides the data into several folds and trains the model on different combinations of these folds. Averaging performance across these folds improves model generalization, reducing overfitting.\n",
        "2. **Early Stopping**: Early stopping monitors performance on a validation set during training and stops once improvement plateaus, preventing the model from learning noise in the data.\n",
        "3. **Regularization**: Adding a penalty for complex model parameters (e.g., L1 or L2 regularization) discourages overfitting by limiting the impact of any one feature, leading to a simpler model with better generalization."
      ],
      "metadata": {
        "id": "gLEkTQwUprTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "Upload your own example image using the \"upload\" button and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "NYuSdJcxp3Xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Load the `torchvision.datasets.MNIST()` train and test datasets."
      ],
      "metadata": {
        "id": "YT3gF_ewxK2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training data\n",
        "train_data_MNIST = datasets.MNIST(\n",
        "    root=\"data\", # where to download data to?\n",
        "    train=True, # get training data\n",
        "    download=True, # download data if it doesn't exist on disk\n",
        "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
        "    target_transform=None # you can transform labels as well\n",
        ")\n",
        "\n",
        "# Setup testing data\n",
        "test_data_MNIST = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # get test data\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "U9iC8gpVyahZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "MEK8rtt-0oap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "cqhvYCyypXt1",
        "outputId": "b2683843-6978-4733-e0b1-4e243b675125"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set the number of samples\n",
        "num_samples = 5\n",
        "\n",
        "# Generate 5 random indices\n",
        "random_indices = random.sample(range(len(train_data_MNIST)), num_samples)\n",
        "\n",
        "# Set up the plot for 5 images in a row\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    image, label = train_data_MNIST[idx]\n",
        "    plt.subplot(1, num_samples, i+1)\n",
        "    plt.imshow(image.squeeze(), cmap=\"gray\") # Squeeze the image and display in grayscale\n",
        "    plt.title(f\"Label: {label}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data_MNIST.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HqXRX842lhJ",
        "outputId": "80a6d0dd-e99b-4f02-e3b5-947ddd74bf99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Turn the MNIST train and test datasets into dataloaders using torch.utils.data.DataLoader, set the batch_size=32."
      ],
      "metadata": {
        "id": "a_L85C29068x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader_MNIST = DataLoader(train_data_MNIST, # dataset to turn into iterable\n",
        "                              batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "                              shuffle=True #shuffle data every epoch?\n",
        "                              )\n",
        "\n",
        "test_dataloader_MNIST = DataLoader(test_data_MNIST,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False\n",
        "                             )\n",
        "\n",
        "# Let's check out what we've created\n",
        "print(f'DataLoader: {train_dataloader_MNIST, test_dataloader_MNIST}')\n",
        "print(f'Length of train dataloader: {len(train_dataloader_MNIST)} batches of {BATCH_SIZE}')\n",
        "print(f'Length of test dataloader: {len(test_dataloader_MNIST)} batches of {BATCH_SIZE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ghdqh3X00_a",
        "outputId": "83a7c15b-4e70-45da-888b-9450a39725f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoader: (<torch.utils.data.dataloader.DataLoader object at 0x7b391a86fa90>, <torch.utils.data.dataloader.DataLoader object at 0x7b391a86fb20>)\n",
            "Length of train dataloader: 1875 batches of 32\n",
            "Length of test dataloader: 313 batches of 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 Recreate `model_2` used in this notebook (the same model from the [CNN Explainer](https://poloclub.github.io/cnn-explainer/) website, also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "ckNdix3b1FbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional neural network\n",
        "class MNISTModelV2(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_2_MNIST = MNISTModelV2(input_shape=1,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)).to(device)\n",
        "model_2_MNIST"
      ],
      "metadata": {
        "id": "smsMN9LXVbfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d0b799-0c59-4cbb-f75b-e52fe059211c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTModelV2(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocYTrsYI1j9i"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}