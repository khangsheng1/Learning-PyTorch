{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/7RG1ipCfXEi/CXlYRDVZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khangsheng1/Learning-PyTorch/blob/main/LearnPyTorch_IO/03_PyTorch_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Computer Vision"
      ],
      "metadata": {
        "id": "W4M4ITT1hCuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Example of Computer Vision](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-computer-vision-problems.png)"
      ],
      "metadata": {
        "id": "WSO-UhmuZVvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [What's going to be covered](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-pytorch-computer-vision-workflow.png)\n",
        "\n",
        "| Topic| Contents|\n",
        "|---|---|\n",
        "| 0. Computer vision libraries in PyTorch| PyTorch has a bunch of built-in helpful computer vision libraries, let's check them out.|\n",
        "| 1. Load data| To practice computer vision, we'll start with some images of different pieces of clothing from [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist).|\n",
        "| 2. Prepare data| We've got some images, let's load them in with a [PyTorch DataLoader](https://pytorch.org/docs/stable/data.html) so we can use them with our training loop.     |\n",
        "| 3. Model 0: Building a baseline model| Here we'll create a multi-class classification model to learn patterns in the data, we'll also choose a **loss function**, **optimizer** and build a **training loop**. |\n",
        "| 4. Making predictions and evaluating model 0| Let's make some predictions with our baseline model and evaluate them.|\n",
        "| 5. Setup device agnostic code for future models     | It's best practice to write device-agnostic code, so let's set it up.|\n",
        "| 6. Model 1: Adding non-linearity| Experimenting is a large part of machine learning, let's try and improve upon our baseline model by adding non-linear layers. |\n",
        "| 7. Model 2: Convolutional Neural Network (CNN)      | Time to get computer vision specific and introduce the powerful convolutional neural network architecture.          |\n",
        "| 8. Comparing our models| We've built three different models, let's compare them. |\n",
        "| 9. Evaluating our best model   | Let's make some predictions on random images and evaluate our best model.                                          |\n",
        "| 10. Making a confusion matrix  | A confusion matrix is a great way to evaluate a classification model, let's see how we can make one. |\n",
        "| 11. Saving and loading the best performing model    | Since we might want to use our model for later, let's save it and make sure it loads back in correctly.            |\n"
      ],
      "metadata": {
        "id": "D6QpJfNKabGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 Computer vision libraries in PyTorch"
      ],
      "metadata": {
        "id": "zEYVHZhUg_xY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| PyTorch module                  | What does it do?                                                                                                             |\n",
        "|----------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
        "| [torchvision](https://pytorch.org/vision/stable/index.html)                      | Contains datasets, model architectures and image transformations often used for computer vision problems.                   |\n",
        "| [torchvision.datasets](https://pytorch.org/vision/stable/datasets.html)              | Here you'll find many example computer vision datasets for a range of problems from image classification, object detection, image captioning, video classification and more. It also contains [a series of base classes for making custom datasets.](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets)  |\n",
        "| [torchvision.models](https://pytorch.org/vision/stable/models.html)                | This module contains well-performing and commonly used computer vision model architectures implemented in PyTorch, you can use these with your own problems.|\n",
        "| [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)            | Often images need to be transformed (turned into numbers/processed/augmented) before being used with a model, common image transformations are found here.|\n",
        "| [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)          | Base dataset class for PyTorch.|\n",
        "| [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#module-torch.utils.data)       | Creates a Python iterable over a dataset (created with torch.utils.data.Dataset).|\n"
      ],
      "metadata": {
        "id": "F_zco9Jyh1fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "id": "5dBUXx5RZRol",
        "outputId": "5c38d25d-63d2-4b68-8dc2-ef29f5dc7e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.4.1+cu121\n",
            "torchvision version: 0.19.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Getting a dataset"
      ],
      "metadata": {
        "id": "IJk5Mjppj8CC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Original MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) contains examples of handwritten digits from 0 to 9"
      ],
      "metadata": {
        "id": "OHXD0462j_bP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we'll use the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset by Zalando Research\n",
        "\n",
        "\n",
        "*   Contains grayscale images of 10 different kinds of clothing\n",
        "\n",
        "[Image Example](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-fashion-mnist-slide.png)\n"
      ],
      "metadata": {
        "id": "5zK1WXy6kJA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to?\n",
        "    train=True, # get training data\n",
        "    download=True, # download data if it doesn't exist on disk\n",
        "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
        "    target_transform=None # you can transform labels as well\n",
        ")\n",
        "\n",
        "# Setup testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # get test data\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "3Wn40E7FkeWB",
        "outputId": "7d16dd49-a89b-4836-93ad-793dfc0045e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:05<00:00, 4827923.72it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 266705.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5073065.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 1026053.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRdGUlvoleM5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}