1. Imports and Setup
      Imported necessary libraries including PyTorch, torchvision, pandas, and others required for dataset loading, transformations, and model training.
      Defined necessary paths and configurations.
2. Downloading and Unzipping the Dataset
      Wrote a function download_and_unzip to download and extract the IAM Handwriting dataset from a URL if it is not already downloaded.
      Checked if the dataset is already present, and if not, downloaded and extracted it.
3. Parsing the Dataset
      Implemented the parse_words_file function to parse the words.txt file that contains metadata (such as image paths and transcriptions).
      Extracted information such as image paths, labels, and transcriptions, and stored them in a pandas DataFrame (df).
4. Created a Custom Dataset Class
      Defined the HandwritingDataset class, which inherits from torch.utils.data.Dataset.
      Implemented methods to:
        Load images and handle missing files by providing a default blank image.
        Apply transformations (such as resizing and normalization) to the images.
        Encode transcriptions into numeric labels based on a character-to-index mapping (char_to_idx).
        Created a vocabulary from the transcriptions for character encoding.
5. Defined Image Transformations
      Used torchvision.transforms.Compose to define a series of transformations:
      Resized images to a standard size (128x32 pixels).
      Converted images to tensors.
  Normalized the image tensors to have mean [0.5] and standard deviation [0.5].
6. Implemented Collate Function
      Created a custom collate_fn to:
      Batch images and labels.
      Pad the labels to match the longest label in each batch to handle sequences of varying lengths.
      Stack the image tensors to form batches.
7. DataLoader Setup
      Defined the dataset using the HandwritingDataset class, with the parsed DataFrame (df) and image directory.
      Set up a DataLoader to handle batching, shuffling, and loading data using the custom collate_fn.
8. Batch Inspection
      Looped through the DataLoader to:
      Load batches of images and labels.
      Printed the shape of the image batch and labels to verify correct data loading.
9. Data Integrity Check
      Verified the total number of samples in the dataset by checking the length of the dataset.
      Checked for missing image paths in the DataFrame, ensuring all images are available.
10. Visualizing Samples
      Implemented the visualize_samples function to:
      Randomly select and display a few image samples with their corresponding transcriptions using matplotlib.
      Verified that the images and transcriptions are paired correctly.
