{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khangsheng1/Learning-PyTorch/blob/main/CC_Fraud_Kaggle/CC_Fraud_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRBtqEJNmI2G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import kaggle\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocs9PQRpmI2G",
        "outputId": "45b1ff37-a8ee-4402-a8b6-b2b0facab633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\khang\\Desktop\\PyTorch Tutorial\\Kaggle Credit Card Fraud\n"
          ]
        }
      ],
      "source": [
        "# Get the current working directory\n",
        "current_path = os.getcwd()\n",
        "print(f'{current_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIzAoI8emI2H",
        "outputId": "f7d2c6ae-dffc-485c-fb23-e82b237d2316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
            "License(s): DbCL-1.0\n",
            "creditcardfraud.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d mlg-ulb/creditcardfraud -p ./datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrBGV8mOmI2H",
        "outputId": "9d4b5249-7cb9-4d97-a8b6-72ebf993420a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files extracted to: ./datasets/extracted/\n"
          ]
        }
      ],
      "source": [
        "# Define the path to your zip file\n",
        "zip_file_path = './datasets/creditcardfraud.zip'\n",
        "extracted_path = './datasets/extracted/'\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(zip_file_path):\n",
        "    # Open the zip file in read mode\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        # Extract all the contents of the zip file to a directory\n",
        "        zip_ref.extractall(extracted_path)\n",
        "        print(f'Files extracted to: {extracted_path}')\n",
        "else:\n",
        "    print(\"Zip file does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXzkl44EmI2H",
        "outputId": "52812118-f4f1-4bcb-9c25-d5d61bfed073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "# Assuming there's a CSV file in the extracted folder\n",
        "csv_file_path = os.path.join(extracted_path, 'creditcard.csv')\n",
        "\n",
        "# Load the CSV into a pandas DataFrame\n",
        "if os.path.exists(csv_file_path):\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    print(df.head())  # Print the first 5 rows of the DataFrame\n",
        "else:\n",
        "    print(\"CSV file not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpmZ5tERmI2H",
        "outputId": "a1bc6207-19ab-40f4-cb7a-bc1e400bf64a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATRfzHC6mI2H",
        "outputId": "ff50dc5b-526c-4c30-fb24-ac3e44b452d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: (284807, 29)\n",
            "Labels shape: (284807,)\n"
          ]
        }
      ],
      "source": [
        "# Separate into X and y\n",
        "X = df.drop(columns=['Time','Class'])\n",
        "y = df['Class']\n",
        "\n",
        "# Check the shape of X and y to ensure they're correct\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhjyNySjmI2I",
        "outputId": "d3a8d234-d5b6-4170-a765-e0cee6b6b4e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check the distribution of the target variable y\n",
        "class_distribution = y.value_counts()\n",
        "\n",
        "print(class_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5pIO_WYmI2I",
        "outputId": "076a4f89-d26e-4c31-f64e-4e366e684184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_tensor shape: torch.Size([227845, 29])\n",
            "X_test_tensor shape: torch.Size([56962, 29])\n",
            "y_train_tensor shape: torch.Size([227845])\n",
            "y_test_tensor shape: torch.Size([56962])\n"
          ]
        }
      ],
      "source": [
        "# Perform an 80/20 train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the DataFrames to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)\n",
        "\n",
        "# Check the shapes of the tensors\n",
        "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
        "print(f\"X_test_tensor shape: {X_test_tensor.shape}\")\n",
        "print(f\"y_train_tensor shape: {y_train_tensor.shape}\")\n",
        "print(f\"y_test_tensor shape: {y_test_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n53_I9H0mI2I",
        "outputId": "02ecd042-5099-47cd-f78d-3ab727ea75dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are using cuda.\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'You are using {device}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI7lhPkEmI2I",
        "outputId": "a5f45ae6-2f49-4ce5-9b7e-58804b487a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_tensor is on: cuda:0\n",
            "X_test_tensor is on: cuda:0\n",
            "y_train_tensor is on: cuda:0\n",
            "y_test_tensor is on: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Move tensors to the appropriate device\n",
        "X_train_tensor = X_train_tensor.to(device)\n",
        "X_test_tensor = X_test_tensor.to(device)\n",
        "y_train_tensor = y_train_tensor.to(device)\n",
        "y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "# Verify the device of the tensors\n",
        "print(f\"X_train_tensor is on: {X_train_tensor.device}\")\n",
        "print(f\"X_test_tensor is on: {X_test_tensor.device}\")\n",
        "print(f\"y_train_tensor is on: {y_train_tensor.device}\")\n",
        "print(f\"y_test_tensor is on: {y_test_tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAtTVfxEmI2I",
        "outputId": "6cf70803-5228-423b-c57e-0cf97ae193d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29\n",
            "2\n",
            "CC_Fraud_Model(\n",
            "  (linear_layer_stack): Sequential(\n",
            "    (0): Linear(in_features=29, out_features=20, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Model is on: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Build model\n",
        "\n",
        "class CC_Fraud_Model(nn.Module):\n",
        "    def __init__(self, input_features, output_features, hidden_units=10):\n",
        "        super().__init__()\n",
        "        self.linear_layer_stack = nn.Sequential(\n",
        "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_layer_stack(x)\n",
        "\n",
        "input_features = X_train_tensor.shape[1]\n",
        "print(input_features)\n",
        "unique_classes = torch.unique(y_test_tensor)\n",
        "unique_classes.numel()\n",
        "print(unique_classes.numel())\n",
        "\n",
        "# Create instance of model\n",
        "model = CC_Fraud_Model(input_features=X_test_tensor.shape[1],output_features=unique_classes.numel(),hidden_units=20)\n",
        "model.to(device)\n",
        "print(model)\n",
        "print(f\"Model is on: {next(model.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP_1atbwmI2I"
      },
      "outputs": [],
      "source": [
        "# Create loss and optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJhrpnrSmI2I"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nefntgLmI2J",
        "outputId": "2c6d55d7-c1eb-45c0-b192-e76e89c0a47b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Target size (torch.Size([227845])) must be the same as input size (torch.Size([227845, 2]))",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[47], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mround(torch\u001b[38;5;241m.\u001b[39msigmoid(y_logits))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 2. Calculate loss and accuracy\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_fn(y_true\u001b[38;5;241m=\u001b[39my_train_tensor,\n\u001b[0;32m     12\u001b[0m                   y_pred\u001b[38;5;241m=\u001b[39my_pred)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 3. Optimizer zero grad\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:725\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\functional.py:3193\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3190\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m-> 3193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
            "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([227845])) must be the same as input size (torch.Size([227845, 2]))"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # 1. Forward pass\n",
        "    y_logits = model(X_train_tensor)\n",
        "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "    # 2. Calculate loss and accuracy\n",
        "    loss = loss_fn(y_logits, y_train_tensor)\n",
        "    acc = accuracy_fn(y_true=y_train_tensor,\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Testing\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        # 1. Forward pass\n",
        "        test_logits = model(X_test_tensor).squeeze()\n",
        "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "        # 2. Calculate loss and accuracy\n",
        "        test_loss = loss_fn(test_logits, y_test_tensor)\n",
        "        test_acc = accuracy_fn(y_true=y_test_tensor,\n",
        "                                y_pred=test_pred)\n",
        "\n",
        "\n",
        "    # Print out what's happening\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMNxLq26mI2J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvuO-zPRmI2J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}